# src/config.yaml
app:
  name: "Agentic RAG Application"
  version: "1.0.0"
  debug: false

# Model Provider Configuration
# Options: "gemini", "huggingface", "openai"
# AIzaSyBvNhT9X4ilJ2MQ0O-J8Ee4ZBmAQayH3Zk
model_provider: "gemini"  # Changed to HuggingFace as primary

# Gemini Configuration (Google AI)
gemini:
  llm:
    # Available models: "gemini-pro", "gemini-1.5-flash", "gemini-1.5-pro" 
    model: "gemini-pro" 
    temperature: 0.1
    max_output_tokens: 2048
    
  embeddings:
    model: "models/embedding-001"
    
  safety_settings:
    - category: "HARM_CATEGORY_HARASSMENT"
      threshold: "BLOCK_MEDIUM_AND_ABOVE"
    - category: "HARM_CATEGORY_HATE_SPEECH"  
      threshold: "BLOCK_MEDIUM_AND_ABOVE"
    - category: "HARM_CATEGORY_SEXUALLY_EXPLICIT"
      threshold: "BLOCK_MEDIUM_AND_ABOVE"
    - category: "HARM_CATEGORY_DANGEROUS_CONTENT"
      threshold: "BLOCK_MEDIUM_AND_ABOVE"



# Hugging Face Configuration
huggingface:
  llm:
    # Options: "microsoft/DialoGPT-medium", "google/flan-t5-large", "meta-llama/Llama-2-7b-chat-hf"
    model: "microsoft/DialoGPT-medium"
    temperature: 0.1
    max_tokens: 1000
    device: "auto"  # auto, cpu, cuda
    
  embeddings:
    # Options: "sentence-transformers/all-MiniLM-L6-v2", "sentence-transformers/all-mpnet-base-v2"
    model: "sentence-transformers/all-MiniLM-L6-v2"
    device: "auto"
    
  question_answering:
    # Specialized QA models
    model: "deepset/roberta-base-squad2" 
    # Alternative: "distilbert-base-cased-distilled-squad"

# OpenAI Configuration (backup option)
openai:
  llm:
    model: "gpt-3.5-turbo"
    temperature: 0.1
    max_tokens: 1000
    
  embeddings:
    model: "text-embedding-3-small"

# Legacy format for backward compatibility
llm:
  provider: "huggingface"  # Changed from gemini
  model: "microsoft/DialoGPT-medium"
  temperature: 0.1
  max_output_tokens: 1000

embeddings:
  provider: "huggingface"  # Changed from gemini
  model: "sentence-transformers/all-MiniLM-L6-v2"
  chunk_size: 1000
  chunk_overlap: 200

vector_store:
  provider: "qdrant"
  collection_name: "documents"
  vector_size: 384  # Updated for sentence-transformers/all-MiniLM-L6-v2
  distance: "cosine"
  host: "localhost"
  port: 6333

retrieval:
  similarity_top_k: 5
  similarity_threshold: 0.7

parsing:
  use_llama_parse: true
  extract_images: false

memory:
  enabled: true
  max_tokens: 4000

# Model Fallback Strategy
fallback:
  enabled: true
  order:
    - "huggingface"
    - "gemini" 
    - "openai"
    
# Performance Settings
performance:
  batch_size: 10
  max_workers: 4
  cache_embeddings: true

